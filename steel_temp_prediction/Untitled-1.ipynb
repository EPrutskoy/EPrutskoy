{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "RANDOM_STATE = 150824\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import mean_absolute_error, make_scorer\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, RandomizedSearchCV, train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from xgboost import XGBRegressor\n",
    "from phik.report import plot_correlation_matrix\n",
    "\n",
    "from sqlalchemy import create_engine, Column, Integer, String, Float, DateTime, text, select, MetaData, Table\n",
    "from sqlalchemy.orm import DeclarativeBase, Session\n",
    "from sqlalchemy.schema import DropTable\n",
    "from sqlalchemy.ext.compiler import compiles\n",
    "\n",
    "# Для LGBMRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.options.display.float_format = '{:.4f}'.format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Инициализация пустого DataFrame для хранения результатов\n",
    "results_df = pd.DataFrame(columns=['Model', 'Best_Score', 'Best_Params'])\n",
    "\n",
    "def add_to_results_table(model_name, best_model, best_score, best_params):\n",
    "    \"\"\"\n",
    "    Добавляет результаты модели в таблицу для сравнения.\n",
    "\n",
    "    Параметры:\n",
    "        model_name (str): Название модели.\n",
    "        best_model: Лучшая модель, найденная в процессе оптимизации.\n",
    "        best_score (float): Лучшее значение MAE, найденное на кросс-валидации.\n",
    "        best_params (dict): Словарь с лучшими гиперпараметрами.\n",
    "\n",
    "    Возвращает:\n",
    "        results_df (pd.DataFrame): Обновленная таблица с результатами моделей.\n",
    "    \"\"\"\n",
    "    global results_df  # Используем глобальную переменную для хранения результатов\n",
    "\n",
    "    # Создаем новую строку с результатами в виде DataFrame\n",
    "    new_row = pd.DataFrame({\n",
    "        'Model': [model_name],\n",
    "        'Best_Score': [best_score],\n",
    "        'Best_Params': [best_params]\n",
    "    })\n",
    "    \n",
    "    # Добавляем строку в DataFrame с использованием pd.concat\n",
    "    results_df = pd.concat([results_df, new_row], ignore_index=True)\n",
    "    \n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>start_temp</th>\n",
       "      <th>target_temp</th>\n",
       "      <th>key_cycles</th>\n",
       "      <th>active_power_mean</th>\n",
       "      <th>active_power_max</th>\n",
       "      <th>active_power_min</th>\n",
       "      <th>active_power_std</th>\n",
       "      <th>active_power_range</th>\n",
       "      <th>reactive_power_mean</th>\n",
       "      <th>apparent_power_std</th>\n",
       "      <th>power_factor_mean</th>\n",
       "      <th>heating_duration_sum</th>\n",
       "      <th>heating_duration_std</th>\n",
       "      <th>energy_consumed_sum</th>\n",
       "      <th>energy_consumed_std</th>\n",
       "      <th>power_diff_mean</th>\n",
       "      <th>heating_duration_diff_mean</th>\n",
       "      <th>power_change_mean</th>\n",
       "      <th>power_change_max</th>\n",
       "      <th>bulk_1</th>\n",
       "      <th>bulk_3</th>\n",
       "      <th>bulk_4</th>\n",
       "      <th>bulk_5</th>\n",
       "      <th>bulk_6</th>\n",
       "      <th>bulk_7</th>\n",
       "      <th>bulk_10</th>\n",
       "      <th>bulk_11</th>\n",
       "      <th>bulk_12</th>\n",
       "      <th>bulk_14</th>\n",
       "      <th>bulk_15</th>\n",
       "      <th>wire_1</th>\n",
       "      <th>wire_2</th>\n",
       "      <th>wire_3</th>\n",
       "      <th>wire_6</th>\n",
       "      <th>gas</th>\n",
       "      <th>bulk_sum</th>\n",
       "      <th>wire_sum</th>\n",
       "      <th>wire_add_count</th>\n",
       "      <th>bulk_add_count</th>\n",
       "      <th>added_sum</th>\n",
       "      <th>add_count_total</th>\n",
       "      <th>bulk_other</th>\n",
       "      <th>wire_other</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>key</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1571.0000</td>\n",
       "      <td>1613.0000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.6073</td>\n",
       "      <td>0.8671</td>\n",
       "      <td>0.3051</td>\n",
       "      <td>0.2194</td>\n",
       "      <td>0.5620</td>\n",
       "      <td>0.4286</td>\n",
       "      <td>0.2682</td>\n",
       "      <td>0.8167</td>\n",
       "      <td>1098.0000</td>\n",
       "      <td>86.3151</td>\n",
       "      <td>770.2821</td>\n",
       "      <td>55.6778</td>\n",
       "      <td>0.1124</td>\n",
       "      <td>-16.0000</td>\n",
       "      <td>-8.0345</td>\n",
       "      <td>-4.2505</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>43.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>206.0000</td>\n",
       "      <td>150.0000</td>\n",
       "      <td>154.0000</td>\n",
       "      <td>60.0600</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>29.7500</td>\n",
       "      <td>553.0000</td>\n",
       "      <td>60.0600</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>613.0600</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1581.0000</td>\n",
       "      <td>1602.0000</td>\n",
       "      <td>4</td>\n",
       "      <td>0.5349</td>\n",
       "      <td>0.7863</td>\n",
       "      <td>0.2617</td>\n",
       "      <td>0.2532</td>\n",
       "      <td>0.5247</td>\n",
       "      <td>0.3633</td>\n",
       "      <td>0.3066</td>\n",
       "      <td>0.8253</td>\n",
       "      <td>811.0000</td>\n",
       "      <td>97.5683</td>\n",
       "      <td>481.7600</td>\n",
       "      <td>58.4605</td>\n",
       "      <td>0.1013</td>\n",
       "      <td>18.2500</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>-7.0075</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>73.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>206.0000</td>\n",
       "      <td>149.0000</td>\n",
       "      <td>154.0000</td>\n",
       "      <td>96.0523</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>12.5556</td>\n",
       "      <td>582.0000</td>\n",
       "      <td>96.0523</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>678.0523</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>1596.0000</td>\n",
       "      <td>1599.0000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.8127</td>\n",
       "      <td>1.2230</td>\n",
       "      <td>0.4217</td>\n",
       "      <td>0.3461</td>\n",
       "      <td>0.8013</td>\n",
       "      <td>0.5875</td>\n",
       "      <td>0.4237</td>\n",
       "      <td>0.8097</td>\n",
       "      <td>655.0000</td>\n",
       "      <td>86.6112</td>\n",
       "      <td>722.8377</td>\n",
       "      <td>137.8374</td>\n",
       "      <td>-0.1360</td>\n",
       "      <td>-43.0000</td>\n",
       "      <td>-4.8065</td>\n",
       "      <td>-2.7065</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>34.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>205.0000</td>\n",
       "      <td>152.0000</td>\n",
       "      <td>153.0000</td>\n",
       "      <td>91.1602</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>28.5548</td>\n",
       "      <td>544.0000</td>\n",
       "      <td>91.1602</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>635.1602</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>1601.0000</td>\n",
       "      <td>1625.0000</td>\n",
       "      <td>4</td>\n",
       "      <td>0.6766</td>\n",
       "      <td>0.8879</td>\n",
       "      <td>0.3107</td>\n",
       "      <td>0.2678</td>\n",
       "      <td>0.5772</td>\n",
       "      <td>0.5142</td>\n",
       "      <td>0.3292</td>\n",
       "      <td>0.7939</td>\n",
       "      <td>741.0000</td>\n",
       "      <td>75.9665</td>\n",
       "      <td>683.4556</td>\n",
       "      <td>107.2103</td>\n",
       "      <td>0.0555</td>\n",
       "      <td>17.7500</td>\n",
       "      <td>-5.7416</td>\n",
       "      <td>-4.6101</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>81.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>207.0000</td>\n",
       "      <td>153.0000</td>\n",
       "      <td>154.0000</td>\n",
       "      <td>89.0635</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>18.8412</td>\n",
       "      <td>595.0000</td>\n",
       "      <td>89.0635</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>684.0635</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>1576.0000</td>\n",
       "      <td>1602.0000</td>\n",
       "      <td>4</td>\n",
       "      <td>0.5632</td>\n",
       "      <td>0.8930</td>\n",
       "      <td>0.3246</td>\n",
       "      <td>0.2423</td>\n",
       "      <td>0.5684</td>\n",
       "      <td>0.4220</td>\n",
       "      <td>0.2967</td>\n",
       "      <td>0.7968</td>\n",
       "      <td>869.0000</td>\n",
       "      <td>151.5484</td>\n",
       "      <td>512.1699</td>\n",
       "      <td>69.2709</td>\n",
       "      <td>0.1421</td>\n",
       "      <td>-45.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>78.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>203.0000</td>\n",
       "      <td>151.0000</td>\n",
       "      <td>152.0000</td>\n",
       "      <td>89.2382</td>\n",
       "      <td>9.1146</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>5.4137</td>\n",
       "      <td>584.0000</td>\n",
       "      <td>98.3528</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>682.3528</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0  start_temp  target_temp  key_cycles  active_power_mean  \\\n",
       "key                                                                       \n",
       "1             0   1571.0000    1613.0000           5             0.6073   \n",
       "2             1   1581.0000    1602.0000           4             0.5349   \n",
       "3             2   1596.0000    1599.0000           5             0.8127   \n",
       "4             3   1601.0000    1625.0000           4             0.6766   \n",
       "5             4   1576.0000    1602.0000           4             0.5632   \n",
       "\n",
       "     active_power_max  active_power_min  active_power_std  active_power_range  \\\n",
       "key                                                                             \n",
       "1              0.8671            0.3051            0.2194              0.5620   \n",
       "2              0.7863            0.2617            0.2532              0.5247   \n",
       "3              1.2230            0.4217            0.3461              0.8013   \n",
       "4              0.8879            0.3107            0.2678              0.5772   \n",
       "5              0.8930            0.3246            0.2423              0.5684   \n",
       "\n",
       "     reactive_power_mean  apparent_power_std  power_factor_mean  \\\n",
       "key                                                               \n",
       "1                 0.4286              0.2682             0.8167   \n",
       "2                 0.3633              0.3066             0.8253   \n",
       "3                 0.5875              0.4237             0.8097   \n",
       "4                 0.5142              0.3292             0.7939   \n",
       "5                 0.4220              0.2967             0.7968   \n",
       "\n",
       "     heating_duration_sum  heating_duration_std  energy_consumed_sum  \\\n",
       "key                                                                    \n",
       "1               1098.0000               86.3151             770.2821   \n",
       "2                811.0000               97.5683             481.7600   \n",
       "3                655.0000               86.6112             722.8377   \n",
       "4                741.0000               75.9665             683.4556   \n",
       "5                869.0000              151.5484             512.1699   \n",
       "\n",
       "     energy_consumed_std  power_diff_mean  heating_duration_diff_mean  \\\n",
       "key                                                                     \n",
       "1                55.6778           0.1124                    -16.0000   \n",
       "2                58.4605           0.1013                     18.2500   \n",
       "3               137.8374          -0.1360                    -43.0000   \n",
       "4               107.2103           0.0555                     17.7500   \n",
       "5                69.2709           0.1421                    -45.0000   \n",
       "\n",
       "     power_change_mean  power_change_max  bulk_1  bulk_3  bulk_4  bulk_5  \\\n",
       "key                                                                        \n",
       "1              -8.0345           -4.2505  0.0000  0.0000 43.0000  0.0000   \n",
       "2               0.0000           -7.0075  0.0000  0.0000 73.0000  0.0000   \n",
       "3              -4.8065           -2.7065  0.0000  0.0000 34.0000  0.0000   \n",
       "4              -5.7416           -4.6101  0.0000  0.0000 81.0000  0.0000   \n",
       "5               0.0000            0.0000  0.0000  0.0000 78.0000  0.0000   \n",
       "\n",
       "     bulk_6  bulk_7  bulk_10  bulk_11  bulk_12  bulk_14  bulk_15  wire_1  \\\n",
       "key                                                                        \n",
       "1    0.0000  0.0000   0.0000   0.0000 206.0000 150.0000 154.0000 60.0600   \n",
       "2    0.0000  0.0000   0.0000   0.0000 206.0000 149.0000 154.0000 96.0523   \n",
       "3    0.0000  0.0000   0.0000   0.0000 205.0000 152.0000 153.0000 91.1602   \n",
       "4    0.0000  0.0000   0.0000   0.0000 207.0000 153.0000 154.0000 89.0635   \n",
       "5    0.0000  0.0000   0.0000   0.0000 203.0000 151.0000 152.0000 89.2382   \n",
       "\n",
       "     wire_2  wire_3  wire_6     gas  bulk_sum  wire_sum  wire_add_count  \\\n",
       "key                                                                       \n",
       "1    0.0000  0.0000  0.0000 29.7500  553.0000   60.0600               4   \n",
       "2    0.0000  0.0000  0.0000 12.5556  582.0000   96.0523               4   \n",
       "3    0.0000  0.0000  0.0000 28.5548  544.0000   91.1602               4   \n",
       "4    0.0000  0.0000  0.0000 18.8412  595.0000   89.0635               4   \n",
       "5    9.1146  0.0000  0.0000  5.4137  584.0000   98.3528               4   \n",
       "\n",
       "     bulk_add_count  added_sum  add_count_total  bulk_other  wire_other  \n",
       "key                                                                      \n",
       "1                 2   613.0600                6      0.0000      0.0000  \n",
       "2                 2   678.0523                6      0.0000      0.0000  \n",
       "3                 2   635.1602                6      0.0000      0.0000  \n",
       "4                 2   684.0635                6      0.0000      0.0000  \n",
       "5                 3   682.3528                7      0.0000      0.0000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Читаем файл обратно\n",
    "final_df = pd.read_csv('final_df.csv', index_col='key')\n",
    "\n",
    "# Проверяем первые несколько строк\n",
    "display(final_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размеры обучающих данных:  (1782, 43) (1782,)\n",
      "Размеры тестовых данных:  (594, 43) (594,)\n"
     ]
    }
   ],
   "source": [
    "# Разделение данных на признаки (X) и таргет (y)\n",
    "X = final_df.drop(columns=['target_temp'])\n",
    "y = final_df['target_temp']\n",
    "\n",
    "# Разделение на обучающую и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Преобразование данных с использованием StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Вывод размеров данных для проверки\n",
    "print(\"Размеры обучающих данных: \", X_train.shape, y_train.shape)\n",
    "print(\"Размеры тестовых данных: \", X_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE LinearRegression =  7.4591\n"
     ]
    }
   ],
   "source": [
    "model_lr = LinearRegression()\n",
    "model_lr.fit(X_train, y_train)\n",
    "mae_lr = round(abs(cross_val_score(model_lr, X=X_train, y=y_train, cv=5, scoring='neg_mean_absolute_error')).mean(), 4)\n",
    "print(f'MAE LinearRegression =  {mae_lr}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_with_cv(model, X, y, cv=5):\n",
    "    \"\"\"\n",
    "    Оценивает модель с использованием кросс-валидации по метрике MAE.\n",
    "\n",
    "    Параметры:\n",
    "        model: Модель для оценки.\n",
    "        X (pd.DataFrame или np.ndarray): Матрица признаков.\n",
    "        y (pd.Series или np.ndarray): Вектор целевой переменной.\n",
    "        cv (int): Количество фолдов для кросс-валидации.\n",
    "\n",
    "    Возвращает:\n",
    "        mean_mae (float): Среднее значение MAE по фолдам кросс-валидации.\n",
    "    \"\"\"\n",
    "    # Используем отрицательный MAE, поскольку в scikit-learn метрики ошибок представлены в отрицательном виде для целей оптимизации\n",
    "    mae_scorer = make_scorer(mean_absolute_error, greater_is_better=False)\n",
    "    \n",
    "    # Выполняем кросс-валидацию\n",
    "    cv_scores = cross_val_score(model, X, y, cv=cv, scoring=mae_scorer, n_jobs=-1)\n",
    "    \n",
    "    # Преобразуем отрицательные значения обратно в положительные\n",
    "    mean_mae = -cv_scores.mean()\n",
    "    std_mae = cv_scores.std()\n",
    "    \n",
    "    print(f\"Среднее MAE на кросс-валидации: {mean_mae:.4f}\")\n",
    "    print(f\"Стандартное отклонение MAE на кросс-валидации: {std_mae:.4f}\")\n",
    "    \n",
    "    return mean_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_model(model, param_distributions, X, y, cv=5, n_iter=50, random_state=42):\n",
    "    \"\"\"\n",
    "    Выполняет подбор гиперпараметров для переданной модели с использованием RandomizedSearchCV.\n",
    "\n",
    "    Параметры:\n",
    "        model: Модель, для которой производится подбор гиперпараметров.\n",
    "        param_distributions (dict): Словарь гиперпараметров для RandomizedSearchCV.\n",
    "        X (pd.DataFrame или np.ndarray): Матрица признаков.\n",
    "        y (pd.Series или np.ndarray): Вектор целевой переменной.\n",
    "        cv (int): Количество фолдов для кросс-валидации.\n",
    "        n_iter (int): Количество итераций для RandomizedSearchCV.\n",
    "        random_state (int): Зерно для генерации случайных чисел.\n",
    "\n",
    "    Возвращает:\n",
    "        best_model: Модель с лучшими найденными гиперпараметрами.\n",
    "        best_score (float): Лучшее найденное значение MAE на кросс-валидации.\n",
    "        best_params (dict): Словарь с лучшими гиперпараметрами.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Настраиваем RandomizedSearchCV\n",
    "    randomized_search = RandomizedSearchCV(\n",
    "        estimator=model,\n",
    "        param_distributions=param_distributions,\n",
    "        n_iter=n_iter,\n",
    "        cv=cv,\n",
    "        scoring=make_scorer(mean_absolute_error, greater_is_better=False),\n",
    "        random_state=random_state,\n",
    "        n_jobs=-1,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Выполняем поиск\n",
    "    randomized_search.fit(X, y)\n",
    "    \n",
    "    # Извлекаем лучшие параметры и модель\n",
    "    best_model = randomized_search.best_estimator_\n",
    "    best_params = randomized_search.best_params_\n",
    "    best_score = -randomized_search.best_score_\n",
    "    \n",
    "    print(\"\\nЛучшие параметры модели:\")\n",
    "    for param_name in best_params:\n",
    "        print(f\" - {param_name}: {best_params[param_name]}\")\n",
    "    \n",
    "    print(f\"\\nЛучшее значение MAE на кросс-валидации: {best_score:.4f}\")\n",
    "    \n",
    "    return best_model, best_score, best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Оценка модели LinearRegression:\n",
      "Среднее MAE на кросс-валидации: 7.3298\n",
      "Стандартное отклонение MAE на кросс-валидации: 0.0673\n"
     ]
    }
   ],
   "source": [
    "# Пример: оценка модели LinearRegression\n",
    "lr_model = LinearRegression()\n",
    "print(\"Оценка модели LinearRegression:\")\n",
    "lr_mae = evaluate_model_with_cv(lr_model, X_train, y_train, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EPrutskoy\\AppData\\Local\\Temp\\ipykernel_23592\\3328997962.py:3: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results_df = pd.concat([results_df, pd.DataFrame({'Model': ['Linear Regression'], 'Best_Score': [mae_lr]})])\n"
     ]
    }
   ],
   "source": [
    "# Добавление результата в таблицу\n",
    "results_df = pd.DataFrame(columns=['Model', 'Best_Score'])\n",
    "results_df = pd.concat([results_df, pd.DataFrame({'Model': ['Linear Regression'], 'Best_Score': [mae_lr]})])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Best_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>7.4591</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Model  Best_Score\n",
       "0  Linear Regression      7.4591"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[76], line 10\u001b[0m\n\u001b[0;32m      1\u001b[0m rf_param_distributions \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m200\u001b[39m, \u001b[38;5;241m300\u001b[39m, \u001b[38;5;241m500\u001b[39m],\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_depth\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m20\u001b[39m, \u001b[38;5;241m30\u001b[39m, \u001b[38;5;241m50\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbootstrap\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28;01mFalse\u001b[39;00m]\n\u001b[0;32m      8\u001b[0m }\n\u001b[1;32m---> 10\u001b[0m best_rf_model, best_rf_score, best_rf_params \u001b[38;5;241m=\u001b[39m optimize_model(\n\u001b[0;32m     11\u001b[0m     RandomForestRegressor(random_state\u001b[38;5;241m=\u001b[39mRANDOM_STATE),\n\u001b[0;32m     12\u001b[0m     rf_param_distributions,\n\u001b[0;32m     13\u001b[0m     X_train,\n\u001b[0;32m     14\u001b[0m     y_train\n\u001b[0;32m     15\u001b[0m )\n\u001b[0;32m     17\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRandomForestRegressor\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Добавляем результаты в таблицу\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[72], line 33\u001b[0m, in \u001b[0;36moptimize_model\u001b[1;34m(model, param_distributions, X, y, cv, n_iter, random_state)\u001b[0m\n\u001b[0;32m     21\u001b[0m randomized_search \u001b[38;5;241m=\u001b[39m RandomizedSearchCV(\n\u001b[0;32m     22\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m     23\u001b[0m     param_distributions\u001b[38;5;241m=\u001b[39mparam_distributions,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     29\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     30\u001b[0m )\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Выполняем поиск\u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m randomized_search\u001b[38;5;241m.\u001b[39mfit(X, y)\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# Извлекаем лучшие параметры и модель\u001b[39;00m\n\u001b[0;32m     36\u001b[0m best_model \u001b[38;5;241m=\u001b[39m randomized_search\u001b[38;5;241m.\u001b[39mbest_estimator_\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    868\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    870\u001b[0m     )\n\u001b[0;32m    872\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 874\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_search(evaluate_candidates)\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    878\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1768\u001b[0m, in \u001b[0;36mRandomizedSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1766\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1767\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1768\u001b[0m     evaluate_candidates(\n\u001b[0;32m   1769\u001b[0m         ParameterSampler(\n\u001b[0;32m   1770\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_distributions, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom_state\n\u001b[0;32m   1771\u001b[0m         )\n\u001b[0;32m   1772\u001b[0m     )\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:821\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    813\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    814\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    815\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    816\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    817\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    818\u001b[0m         )\n\u001b[0;32m    819\u001b[0m     )\n\u001b[1;32m--> 821\u001b[0m out \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[0;32m    822\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    823\u001b[0m         clone(base_estimator),\n\u001b[0;32m    824\u001b[0m         X,\n\u001b[0;32m    825\u001b[0m         y,\n\u001b[0;32m    826\u001b[0m         train\u001b[38;5;241m=\u001b[39mtrain,\n\u001b[0;32m    827\u001b[0m         test\u001b[38;5;241m=\u001b[39mtest,\n\u001b[0;32m    828\u001b[0m         parameters\u001b[38;5;241m=\u001b[39mparameters,\n\u001b[0;32m    829\u001b[0m         split_progress\u001b[38;5;241m=\u001b[39m(split_idx, n_splits),\n\u001b[0;32m    830\u001b[0m         candidate_progress\u001b[38;5;241m=\u001b[39m(cand_idx, n_candidates),\n\u001b[0;32m    831\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_and_score_kwargs,\n\u001b[0;32m    832\u001b[0m     )\n\u001b[0;32m    833\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[38;5;129;01min\u001b[39;00m product(\n\u001b[0;32m    834\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(candidate_params), \u001b[38;5;28menumerate\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X, y, groups))\n\u001b[0;32m    835\u001b[0m     )\n\u001b[0;32m    836\u001b[0m )\n\u001b[0;32m    838\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    839\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    840\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    841\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    842\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    843\u001b[0m     )\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     62\u001b[0m )\n\u001b[1;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1095\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1097\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1098\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretrieve()\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;66;03m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_time\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    973\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    974\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupports_timeout\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m--> 975\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout))\n\u001b[0;32m    976\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    977\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget())\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\joblib\\_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    564\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[0;32m    565\u001b[0m \u001b[38;5;124;03mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[0;32m    566\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 567\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m future\u001b[38;5;241m.\u001b[39mresult(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[0;32m    568\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CfTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    569\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\concurrent\\futures\\_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m    449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[1;32m--> 451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[0;32m    454\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\threading.py:327\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 327\u001b[0m         waiter\u001b[38;5;241m.\u001b[39macquire()\n\u001b[0;32m    328\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    329\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "rf_param_distributions = {\n",
    "    'n_estimators': [100, 200, 300, 500],\n",
    "    'max_depth': [None, 10, 20, 30, 50],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "best_rf_model, best_rf_score, best_rf_params = optimize_model(\n",
    "    RandomForestRegressor(random_state=RANDOM_STATE),\n",
    "    rf_param_distributions,\n",
    "    X_train,\n",
    "    y_train\n",
    ")\n",
    "\n",
    "model_name = \"RandomForestRegressor\"\n",
    "# Добавляем результаты в таблицу\n",
    "results_df = add_to_results_table(model_name, best_rf_model, best_rf_score, best_rf_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"RandomForestRegressor\"\n",
    "# Добавляем результаты в таблицу\n",
    "results_df = add_to_results_table(model_name, best_rf_model, best_rf_score, best_rf_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "\n",
      "Лучшие параметры модели:\n",
      " - learning_rate: 0.05\n",
      " - l2_leaf_reg: 7\n",
      " - iterations: 500\n",
      " - depth: 4\n",
      "\n",
      "Лучшее значение MAE на кросс-валидации: 6.0424\n"
     ]
    }
   ],
   "source": [
    "# Для CatBoostRegressor\n",
    "cb_param_distributions = {\n",
    "    'iterations': [100, 200, 500],\n",
    "    'depth': [4, 6, 10],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'l2_leaf_reg': [1, 3, 5, 7, 9]\n",
    "}\n",
    "\n",
    "best_cb_model, best_cb_score, best_cb_params = optimize_model(\n",
    "    CatBoostRegressor(random_state=RANDOM_STATE, silent=True),\n",
    "    cb_param_distributions,\n",
    "    X_train,\n",
    "    y_train, n_iter=15\n",
    ")\n",
    "\n",
    "model_name = 'CatBoostRegressor'\n",
    "results_df = add_to_results_table(model_name, best_cb_model, best_cb_score, best_cb_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000677 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6701\n",
      "[LightGBM] [Info] Number of data points in the train set: 1782, number of used features: 39\n",
      "[LightGBM] [Info] Start training from score 1594.654882\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "\n",
      "Лучшие параметры модели:\n",
      " - num_leaves: 40\n",
      " - n_estimators: 100\n",
      " - min_child_samples: 30\n",
      " - max_depth: 10\n",
      " - learning_rate: 0.05\n",
      "\n",
      "Лучшее значение MAE на кросс-валидации: 6.3712\n"
     ]
    }
   ],
   "source": [
    "lgb_param_distributions = {\n",
    "    'n_estimators': [100, 200, 300, 500],\n",
    "    'max_depth': [None, 10, 20, 30, 50],\n",
    "    'learning_rate': [0.001, 0.05, 0.1],\n",
    "    'num_leaves': [30, 40, 50],\n",
    "    'min_child_samples': [20, 30, 50]\n",
    "}\n",
    "\n",
    "best_lgb_model, best_lgb_score, best_lgb_params = optimize_model(\n",
    "    LGBMRegressor(random_state=RANDOM_STATE),\n",
    "    lgb_param_distributions,\n",
    "    X_train,\n",
    "    y_train, n_iter=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'LGBMRegressor'\n",
    "results_df = add_to_results_table(model_name, best_lgb_model, best_lgb_score, best_lgb_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Best_Score</th>\n",
       "      <th>Best_Params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>7.4591</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>6.2576</td>\n",
       "      <td>{'n_estimators': 200, 'min_samples_split': 10,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CatBoostRegressor</td>\n",
       "      <td>6.0424</td>\n",
       "      <td>{'learning_rate': 0.05, 'l2_leaf_reg': 7, 'ite...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LGBMRegressor</td>\n",
       "      <td>6.3712</td>\n",
       "      <td>{'num_leaves': 40, 'n_estimators': 100, 'min_c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Model  Best_Score  \\\n",
       "0      Linear Regression      7.4591   \n",
       "1  RandomForestRegressor      6.2576   \n",
       "2      CatBoostRegressor      6.0424   \n",
       "3          LGBMRegressor      6.3712   \n",
       "\n",
       "                                         Best_Params  \n",
       "0                                                NaN  \n",
       "1  {'n_estimators': 200, 'min_samples_split': 10,...  \n",
       "2  {'learning_rate': 0.05, 'l2_leaf_reg': 7, 'ite...  \n",
       "3  {'num_leaves': 40, 'n_estimators': 100, 'min_c...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "\n",
      "Лучшие параметры модели:\n",
      " - subsample: 0.8\n",
      " - reg_lambda: 0.1\n",
      " - reg_alpha: 1\n",
      " - n_estimators: 100\n",
      " - max_depth: 3\n",
      " - learning_rate: 0.1\n",
      " - gamma: 0.1\n",
      " - colsample_bytree: 1.0\n",
      "\n",
      "Лучшее значение MAE на кросс-валидации: 6.1046\n"
     ]
    }
   ],
   "source": [
    "# Настраиваем гиперпараметры для XGBRegressor\n",
    "param_distributions_xgb = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.001, 0.01, 0.1],\n",
    "    'subsample': [0.7, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.7, 0.8, 1.0],\n",
    "    'gamma': [0, 0.1, 0.2],\n",
    "    'reg_alpha': [0, 0.1, 1],\n",
    "    'reg_lambda': [1, 0.1, 10]\n",
    "}\n",
    "\n",
    "# Оптимизация модели XGBRegressor\n",
    "best_model_xgb, best_score_xgb, best_params_xgb = optimize_model(XGBRegressor(), \n",
    "                                                                 param_distributions_xgb, \n",
    "                                                                 X_train, \n",
    "                                                                 y_train,\n",
    "                                                                 n_iter=25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Best_Score</th>\n",
       "      <th>Best_Params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>7.4591</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>6.2576</td>\n",
       "      <td>{'n_estimators': 200, 'min_samples_split': 10,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CatBoostRegressor</td>\n",
       "      <td>6.0424</td>\n",
       "      <td>{'learning_rate': 0.05, 'l2_leaf_reg': 7, 'ite...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LGBMRegressor</td>\n",
       "      <td>6.3712</td>\n",
       "      <td>{'num_leaves': 40, 'n_estimators': 100, 'min_c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>6.3712</td>\n",
       "      <td>{'num_leaves': 40, 'n_estimators': 100, 'min_c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>6.3712</td>\n",
       "      <td>{'num_leaves': 40, 'n_estimators': 100, 'min_c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>6.3712</td>\n",
       "      <td>{'num_leaves': 40, 'n_estimators': 100, 'min_c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>6.1046</td>\n",
       "      <td>{'subsample': 0.8, 'reg_lambda': 0.1, 'reg_alp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Model  Best_Score  \\\n",
       "0      Linear Regression      7.4591   \n",
       "1  RandomForestRegressor      6.2576   \n",
       "2      CatBoostRegressor      6.0424   \n",
       "3          LGBMRegressor      6.3712   \n",
       "4           XGBRegressor      6.3712   \n",
       "5           XGBRegressor      6.3712   \n",
       "6           XGBRegressor      6.3712   \n",
       "7           XGBRegressor      6.1046   \n",
       "\n",
       "                                         Best_Params  \n",
       "0                                                NaN  \n",
       "1  {'n_estimators': 200, 'min_samples_split': 10,...  \n",
       "2  {'learning_rate': 0.05, 'l2_leaf_reg': 7, 'ite...  \n",
       "3  {'num_leaves': 40, 'n_estimators': 100, 'min_c...  \n",
       "4  {'num_leaves': 40, 'n_estimators': 100, 'min_c...  \n",
       "5  {'num_leaves': 40, 'n_estimators': 100, 'min_c...  \n",
       "6  {'num_leaves': 40, 'n_estimators': 100, 'min_c...  \n",
       "7  {'subsample': 0.8, 'reg_lambda': 0.1, 'reg_alp...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_df = add_to_results_table('XGBRegressor', best_model_xgb, best_score_xgb, best_params_xgb)\n",
    "\n",
    "# Выводим таблицу сравнения\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Нейросеть"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим последовательную нейросеть."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Best_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>7.4591</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Model  Best_Score\n",
       "0  Linear Regression      7.4591"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
