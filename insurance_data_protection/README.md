# Защита персональных данных клиентов

Вам нужно защитить данные клиентов страховой компании «Хоть потоп». Разработайте такой метод преобразования данных, чтобы по ним было сложно восстановить персональную информацию. Обоснуйте корректность его работы.

Нужно защитить данные, чтобы при преобразовании качество моделей машинного обучения не ухудшилось. Подбирать наилучшую модель не требуется.

## Умножение матриц

**Обоснование:**

Для ответа на вопрос используем формулы линейной регрессии и рассмотрим, как умножение признаков на обратимую матрицу $P$ влияет на вектор весов $w$ и качество линейной регрессии. Предположим, что после преобразования признаков их матрица будет $X' = XP$, где $X$ — исходная матрица признаков, а $P$ — обратимая матрица.

**Исходная формула обучения:**

$$
w = (X^T X)^{-1} X^T y
$$

**Преобразованная формула обучения:**

После преобразования признаков матрица признаков становится $X' = XP$. Тогда новый вектор весов $w'$ для преобразованной задачи будет выглядеть следующим образом:

$$
w' = ((XP)^T XP)^{-1} (XP)^T y
$$

**Раскроем транспонирование произведения матриц:**
$$
w' = (P^T X^T XP)^{-1} P^T X^T y
$$

**Так как $P$ — обратимая матрица, то $P^T$ также обратима. Раскроем обратную матрицу произведения:**

$$
w' = P^{-1} (X^T X)^{-1} (P^T)^{-1} P^T X^T y
$$

**Так как $(P^T)^{-1} P^T = I$, где $I$ — единичная матрица, упрощаем выражение:**

$$
w' = P^{-1} (X^T X)^{-1} X^T y
$$

**Заметим, что последняя часть равенства — это исходный вектор весов $w$:**

$$
w' = P^{-1} w
$$

**Вывод:**

Качество линейной регрессии не изменится после умножения признаков на обратимую матрицу и последующего обучения, так как преобразование признаков с помощью обратимой матрицы лишь изменяет пространство признаков, сохраняя связь между исходными признаками и целевой переменной. Параметры линейной регрессии в преобразованной задаче связаны с исходными параметрами через обратимую матрицу $P$, как показано в формуле $w' = P^{-1} w$. Это означает, что каждый новый вес является линейной комбинацией исходных весов, адаптированных под преобразование признаков, не влияя на качество модели в терминах, например, среднеквадратичной ошибки или коэффициента детерминации $R^2$.


## Алгоритм преобразования

Для решения задачи преобразования данных, сохраняя качество линейной регрессии, можно использовать метод шифрования данных с помощью обратимой матрицы. Это позволяет преобразовать данные таким образом, чтобы исходные связи между признаками и целевой переменной остались неизменными, а значит, качество модели линейной регрессии также не изменится.

**Алгоритм:**

1. Генерация обратимой матрицы $P$ размером $(n \times n)$, где $n$ — количество признаков в исходном наборе данных. Матрица должна быть обратимой, чтобы обеспечить возможность восстановления исходных данных.
 2. Умножение исходной матрицы признаков $X$ на матрицу $P$ для получения преобразованной матрицы признаков $X’ = XP$.
 3. Обучение модели линейной регрессии на преобразованных данных $X’$ и оценка качества модели так же, как и для исходных данных.


**Обоснование:**

Как было показано в предыдущем ответе, преобразованные данные с использованием обратимой матрицы $P$ приведут к новому вектору весов $w’ = P^{-1} w$, где $w$ — вектор весов, обученный на исходных данных.
 
Это преобразование не влияет на качество модели по следующим причинам:

* **Сохранение структуры данных:** Преобразование с использованием обратимой матрицы изменяет пространство признаков, но сохраняет линейные связи между признаками и целевой переменной, что является ключевым для линейной регрессии.

* **Восстановление:** Благодаря использованию обратимой матрицы, преобразование является обратимым, что означает возможность восстановления исходных данных и, соответственно, сохранение качества модели.

**Перейдём к реализации.**